{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "code",
            "source": [
                "# Efficacy: https://www.hindawi.com/journals/scn/2018/5483472/#conclusions \r\n",
                "# Source: https://www.kaggle.com/anishpai/intro-to-credit-card-fraud-detection \r\n",
                "# Data Source: https://www.kaggle.com/mlg-ulb/creditcardfraud \r\n",
                "\r\n",
                "# Library Loads\r\n",
                "import numpy as np\r\n",
                "import matplotlib.pyplot as plt\r\n",
                "import keras\r\n",
                "import pandas as pd\r\n",
                "data = pd.read_csv('https://sabwoody.blob.core.windows.net/backups/creditcard.csv')\r\n",
                "\r\n",
                "# Data Descriptions\r\n",
                "data.head()\r\n",
                "data.dtypes\r\n",
                "data.describe()"
            ],
            "metadata": {
                "azdata_cell_guid": "d3e5be97-f9b9-4418-ab5d-78d7ea9697a3"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "                Time            V1            V2            V3            V4  \\\ncount  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean    94813.859575  1.165980e-15  3.416908e-16 -1.373150e-15  2.086869e-15   \nstd     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \nmin         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \nmax    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n\n                 V5            V6            V7            V8            V9  \\\ncount  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean   9.604066e-16  1.490107e-15 -5.556467e-16  1.177556e-16 -2.406455e-15   \nstd    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \nmin   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \nmax    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n\n       ...           V21           V22           V23           V24  \\\ncount  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean   ...  1.656562e-16 -3.444850e-16  2.578648e-16  4.471968e-15   \nstd    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \nmin    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \nmax    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n\n                V25           V26           V27           V28         Amount  \\\ncount  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \nmean   5.340915e-16  1.687098e-15 -3.666453e-16 -1.220404e-16      88.349619   \nstd    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \nmin   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \nmax    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n\n               Class  \ncount  284807.000000  \nmean        0.001727  \nstd         0.041527  \nmin         0.000000  \n25%         0.000000  \n50%         0.000000  \n75%         0.000000  \nmax         1.000000  \n\n[8 rows x 31 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>284807.000000</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>...</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>284807.000000</td>\n      <td>284807.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>94813.859575</td>\n      <td>1.165980e-15</td>\n      <td>3.416908e-16</td>\n      <td>-1.373150e-15</td>\n      <td>2.086869e-15</td>\n      <td>9.604066e-16</td>\n      <td>1.490107e-15</td>\n      <td>-5.556467e-16</td>\n      <td>1.177556e-16</td>\n      <td>-2.406455e-15</td>\n      <td>...</td>\n      <td>1.656562e-16</td>\n      <td>-3.444850e-16</td>\n      <td>2.578648e-16</td>\n      <td>4.471968e-15</td>\n      <td>5.340915e-16</td>\n      <td>1.687098e-15</td>\n      <td>-3.666453e-16</td>\n      <td>-1.220404e-16</td>\n      <td>88.349619</td>\n      <td>0.001727</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>47488.145955</td>\n      <td>1.958696e+00</td>\n      <td>1.651309e+00</td>\n      <td>1.516255e+00</td>\n      <td>1.415869e+00</td>\n      <td>1.380247e+00</td>\n      <td>1.332271e+00</td>\n      <td>1.237094e+00</td>\n      <td>1.194353e+00</td>\n      <td>1.098632e+00</td>\n      <td>...</td>\n      <td>7.345240e-01</td>\n      <td>7.257016e-01</td>\n      <td>6.244603e-01</td>\n      <td>6.056471e-01</td>\n      <td>5.212781e-01</td>\n      <td>4.822270e-01</td>\n      <td>4.036325e-01</td>\n      <td>3.300833e-01</td>\n      <td>250.120109</td>\n      <td>0.041527</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-5.640751e+01</td>\n      <td>-7.271573e+01</td>\n      <td>-4.832559e+01</td>\n      <td>-5.683171e+00</td>\n      <td>-1.137433e+02</td>\n      <td>-2.616051e+01</td>\n      <td>-4.355724e+01</td>\n      <td>-7.321672e+01</td>\n      <td>-1.343407e+01</td>\n      <td>...</td>\n      <td>-3.483038e+01</td>\n      <td>-1.093314e+01</td>\n      <td>-4.480774e+01</td>\n      <td>-2.836627e+00</td>\n      <td>-1.029540e+01</td>\n      <td>-2.604551e+00</td>\n      <td>-2.256568e+01</td>\n      <td>-1.543008e+01</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>54201.500000</td>\n      <td>-9.203734e-01</td>\n      <td>-5.985499e-01</td>\n      <td>-8.903648e-01</td>\n      <td>-8.486401e-01</td>\n      <td>-6.915971e-01</td>\n      <td>-7.682956e-01</td>\n      <td>-5.540759e-01</td>\n      <td>-2.086297e-01</td>\n      <td>-6.430976e-01</td>\n      <td>...</td>\n      <td>-2.283949e-01</td>\n      <td>-5.423504e-01</td>\n      <td>-1.618463e-01</td>\n      <td>-3.545861e-01</td>\n      <td>-3.171451e-01</td>\n      <td>-3.269839e-01</td>\n      <td>-7.083953e-02</td>\n      <td>-5.295979e-02</td>\n      <td>5.600000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>84692.000000</td>\n      <td>1.810880e-02</td>\n      <td>6.548556e-02</td>\n      <td>1.798463e-01</td>\n      <td>-1.984653e-02</td>\n      <td>-5.433583e-02</td>\n      <td>-2.741871e-01</td>\n      <td>4.010308e-02</td>\n      <td>2.235804e-02</td>\n      <td>-5.142873e-02</td>\n      <td>...</td>\n      <td>-2.945017e-02</td>\n      <td>6.781943e-03</td>\n      <td>-1.119293e-02</td>\n      <td>4.097606e-02</td>\n      <td>1.659350e-02</td>\n      <td>-5.213911e-02</td>\n      <td>1.342146e-03</td>\n      <td>1.124383e-02</td>\n      <td>22.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>139320.500000</td>\n      <td>1.315642e+00</td>\n      <td>8.037239e-01</td>\n      <td>1.027196e+00</td>\n      <td>7.433413e-01</td>\n      <td>6.119264e-01</td>\n      <td>3.985649e-01</td>\n      <td>5.704361e-01</td>\n      <td>3.273459e-01</td>\n      <td>5.971390e-01</td>\n      <td>...</td>\n      <td>1.863772e-01</td>\n      <td>5.285536e-01</td>\n      <td>1.476421e-01</td>\n      <td>4.395266e-01</td>\n      <td>3.507156e-01</td>\n      <td>2.409522e-01</td>\n      <td>9.104512e-02</td>\n      <td>7.827995e-02</td>\n      <td>77.165000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>172792.000000</td>\n      <td>2.454930e+00</td>\n      <td>2.205773e+01</td>\n      <td>9.382558e+00</td>\n      <td>1.687534e+01</td>\n      <td>3.480167e+01</td>\n      <td>7.330163e+01</td>\n      <td>1.205895e+02</td>\n      <td>2.000721e+01</td>\n      <td>1.559499e+01</td>\n      <td>...</td>\n      <td>2.720284e+01</td>\n      <td>1.050309e+01</td>\n      <td>2.252841e+01</td>\n      <td>4.584549e+00</td>\n      <td>7.519589e+00</td>\n      <td>3.517346e+00</td>\n      <td>3.161220e+01</td>\n      <td>3.384781e+01</td>\n      <td>25691.160000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 31 columns</p>\n</div>"
                    },
                    "metadata": {},
                    "execution_count": 1,
                    "output_type": "execute_result"
                }
            ],
            "execution_count": 1
        },
        {
            "cell_type": "code",
            "source": [
                "# Deal with missing data\r\n",
                "data.isnull().sum()\r\n",
                "data.describe()\r\n",
                "\r\n",
                "# Show percentages of + versus - in training set\r\n",
                "print('No Fraud detected is ', round(data['Class'].value_counts()[0]/len(data) * 100,2), '% of the dataset')\r\n",
                "print('Fraud detected is  ', round(data['Class'].value_counts()[1]/len(data) * 100,2), '% of the dataset')\r\n",
                "print('(Fraudulent Transactions: ', data['Class'].value_counts()[1], ' out of ', data['Class'].value_counts()[0], ' records)')"
            ],
            "metadata": {
                "azdata_cell_guid": "6824a2a2-a9b1-4984-b1d2-4a8b93c3e630"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "No Fraud detected is  99.83 % of the dataset\nFraud detected is   0.17 % of the dataset\n(Fraudulent Transactions:  492  out of  284315  records)\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 26
        },
        {
            "cell_type": "code",
            "source": [
                "# Machine Learning approach - data prep\r\n",
                "\r\n",
                "## Let's deal with outliers first\r\n",
                "from sklearn.preprocessing import StandardScaler, RobustScaler\r\n",
                "std_scaler = StandardScaler()\r\n",
                "rob_scaler = RobustScaler()\r\n",
                "data['scaled_amount'] = rob_scaler.fit_transform(data['Amount'].values.reshape(-1,1))\r\n",
                "data['scaled_time'] = rob_scaler.fit_transform(data['Time'].values.reshape(-1,1))"
            ],
            "metadata": {
                "azdata_cell_guid": "833083e8-9045-412b-93d1-722d483ace27"
            },
            "outputs": [],
            "execution_count": 27
        },
        {
            "cell_type": "code",
            "source": [
                "## More data cleaning, prep for graphics if desired\r\n",
                "data.drop(['Time','Amount'], axis=1, inplace=True)\r\n",
                "amount = data['scaled_amount']\r\n",
                "time = data['scaled_time']\r\n",
                "data.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\r\n",
                "data.insert(0, 'amount', amount)\r\n",
                "data.insert(1, 'time', time)\r\n",
                "\r\n",
                "# Examine data cleaned so far:\r\n",
                "data.head()"
            ],
            "metadata": {
                "azdata_cell_guid": "4e2264dd-3a81-4e7f-803c-f7c76303351f"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "     amount      time        V1        V2        V3        V4        V5  \\\n0  1.783274 -0.994983 -1.359807 -0.072781  2.536347  1.378155 -0.338321   \n1 -0.269825 -0.994983  1.191857  0.266151  0.166480  0.448154  0.060018   \n2  4.983721 -0.994972 -1.358354 -1.340163  1.773209  0.379780 -0.503198   \n3  1.418291 -0.994972 -0.966272 -0.185226  1.792993 -0.863291 -0.010309   \n4  0.670579 -0.994960 -1.158233  0.877737  1.548718  0.403034 -0.407193   \n\n         V6        V7        V8  ...       V20       V21       V22       V23  \\\n0  0.462388  0.239599  0.098698  ...  0.251412 -0.018307  0.277838 -0.110474   \n1 -0.082361 -0.078803  0.085102  ... -0.069083 -0.225775 -0.638672  0.101288   \n2  1.800499  0.791461  0.247676  ...  0.524980  0.247998  0.771679  0.909412   \n3  1.247203  0.237609  0.377436  ... -0.208038 -0.108300  0.005274 -0.190321   \n4  0.095921  0.592941 -0.270533  ...  0.408542 -0.009431  0.798278 -0.137458   \n\n        V24       V25       V26       V27       V28  Class  \n0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n4  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n\n[5 rows x 31 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>amount</th>\n      <th>time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>...</th>\n      <th>V20</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.783274</td>\n      <td>-0.994983</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>...</td>\n      <td>0.251412</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.269825</td>\n      <td>-0.994983</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>...</td>\n      <td>-0.069083</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.983721</td>\n      <td>-0.994972</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>...</td>\n      <td>0.524980</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.418291</td>\n      <td>-0.994972</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>...</td>\n      <td>-0.208038</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.670579</td>\n      <td>-0.994960</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>...</td>\n      <td>0.408542</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"
                    },
                    "metadata": {},
                    "execution_count": 28,
                    "output_type": "execute_result"
                }
            ],
            "execution_count": 28
        },
        {
            "cell_type": "code",
            "source": [
                "data = data.sample(frac=1)\r\n",
                "\r\n",
                "fraud_data = data.loc[data['Class']==1]\r\n",
                "nfraud_data = data.loc[data['Class']==0][:492]\r\n",
                "\r\n",
                "normal_distributed_df = pd.concat([fraud_data, nfraud_data])\r\n",
                "\r\n",
                "# Shuffle dataframe rows\r\n",
                "ndata = normal_distributed_df.sample(frac=1, random_state=42)\r\n",
                "ndata.head()\r\n",
                "\r\n",
                "print('Fraudulent Transactions', data['Class'].value_counts()[1])\r\n",
                "print('Non-Fraudulent Transactions', data['Class'].value_counts()[0])"
            ],
            "metadata": {
                "azdata_cell_guid": "331e5359-2d62-4b92-b47a-9f687d0490ec"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Fraudulent Transactions 492\nNon-Fraudulent Transactions 284315\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 30
        },
        {
            "cell_type": "code",
            "source": [
                "X= data.iloc[:, data.columns != 'Class']\r\n",
                "y = data.iloc[:, data.columns == 'Class']\r\n",
                "\r\n",
                "dataframe = pd.DataFrame(data=ndata)\r\n",
                "\r\n",
                "dataframe\r\n",
                "\r\n",
                "X= dataframe.iloc[:, ndata.columns != 'Class']\r\n",
                "y = dataframe.iloc[:, ndata.columns == 'Class']\r\n",
                "\r\n",
                "from sklearn.model_selection import train_test_split\r\n",
                "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.25, random_state=1)\r\n",
                "\r\n",
                "X_train = np.array(X_train)\r\n",
                "X_test = np.array(X_test)\r\n",
                "y_train = np.array(y_train)\r\n",
                "y_test = np.array(y_test)\r\n",
                "\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "b918157e-e680-44b4-86f7-fae923358669"
            },
            "outputs": [],
            "execution_count": 31
        },
        {
            "cell_type": "code",
            "source": [
                "from sklearn.tree import DecisionTreeClassifier\r\n",
                "classifier = DecisionTreeClassifier(criterion = 'gini', random_state= 0 )\r\n",
                "classifier.fit(X_train, y_train.ravel())\r\n",
                "from sklearn.metrics import classification_report, confusion_matrix\r\n",
                "\r\n",
                "cm_grid = confusion_matrix(y_test,y_pre)\r\n",
                "y_pre = classifier.predict(X_test)\r\n",
                "print(classification_report(y_test,y_pre))\r\n",
                "\r\n",
                "classifier.score(X_test,y_test)\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "912961a2-748c-4bcc-adfc-b66740414db9"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "              precision    recall  f1-score   support\n\n           0       0.90      0.93      0.91       121\n           1       0.93      0.90      0.91       125\n\n    accuracy                           0.91       246\n   macro avg       0.91      0.91      0.91       246\nweighted avg       0.91      0.91      0.91       246\n\n",
                    "output_type": "stream"
                },
                {
                    "data": {
                        "text/plain": "0.9146341463414634"
                    },
                    "metadata": {},
                    "execution_count": 32,
                    "output_type": "execute_result"
                }
            ],
            "execution_count": 32
        },
        {
            "cell_type": "code",
            "source": [
                "from keras.models import Sequential\r\n",
                "from keras.layers import Dense\r\n",
                "from keras.layers import Dropout\r\n",
                "\r\n",
                "\r\n",
                "#Initializing ANN\r\n",
                "classifier = Sequential()\r\n",
                "\r\n",
                "#Input Layer\r\n",
                "classifier.add(Dense(30, activation='relu'))\r\n",
                "#2nd layer\r\n",
                "classifier.add(Dense(16, activation='relu'))\r\n",
                "classifier.add(Dense(16, activation='relu'))\r\n",
                "\r\n",
                "#Output layer\r\n",
                "classifier.add(Dense(1, activation='sigmoid'))\r\n",
                "\r\n",
                "#Compling the ANN\r\n",
                "classifier.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\r\n",
                "\r\n",
                "#Fitting the dataset into ANN\r\n",
                "classifier.fit(X_train, y_train, batch_size=100, epochs=100, verbose = 0)\r\n",
                "\r\n",
                "score = classifier.evaluate(X_test, y_test, verbose = 0) \r\n",
                "print('Test loss:', score[0]) \r\n",
                "print('Test accuracy:', score[1])\r\n",
                "\r\n",
                "#Predicting the results\r\n",
                "y_pred = classifier.predict(X_test)\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "331c8393-bd9a-493c-8c89-8ad7716e0f82"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Test loss: 0.33069172501564026\nTest accuracy: 0.9268292784690857\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 33
        }
    ]
}