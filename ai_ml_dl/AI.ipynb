{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "<img style=\"text-align:left;\" src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/solutions-microsoft-logo-small.png?raw=true\" alt=\"Microsoft\">\r\n",
                "<br>\r\n",
                "\r\n",
                "# Azure Cognitive Services Example\r\n",
                "## Text Analysis with pre-built AI\r\n",
                "\r\n",
                "In this example you will get a brief introduction to text analytics in Python with the [pre-built AI in Azure Cognitive Services for text](https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/overview). You can read more about [this example here.](https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/quickstarts/python)\r\n",
                "\r\n",
                "You'll need an Azure subscription, and then you can set up the Text Analysis Services.\r\n",
                "\r\n",
                "The workflow is simple: you submit data for analysis and handle outputs in your code. Analyzers are consumed as-is, with no additional configuration or customization.\r\n",
                "\r\n",
                "- [Create an Azure resource for Text Analytics](https://docs.microsoft.com/en-us/azure/cognitive-services/cognitive-services-apis-create-account). Afterwards, [get the key generated for you to authenticate your requests](https://docs.microsoft.com/en-us/azure/cognitive-services/cognitive-services-apis-create-account#get-the-keys-for-your-resource).\r\n",
                "- [Formulate a request containing your data](https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/how-tos/text-analytics-how-to-call-api#json-schema) as raw unstructured text, in JSON.\r\n",
                "- Post the request to the endpoint established during sign-up, appending the desired resource: sentiment analysis, key phrase extraction, language detection, or entity identification.\r\n",
                "- Stream or store the response locally. Depending on the request, results are either a sentiment score, a collection of extracted key phrases, or a language code.\r\n",
                "\r\n",
                "The output is returned as a single JSON document, with results for each text document you posted, based on ID. You can subsequently analyze, visualize, or categorize the results into actionable insights - Data is not stored in your account. Operations performed by the Text Analytics API are stateless, which means the text you provide is processed and results are returned immediately. \r\n",
                "\r\n",
                "As an example, let's see how we could use Text Analysis in a larger effort to monitor social media for issues:\r\n",
                "\r\n",
                "<img style=\"text-align:left; height: 100px;\"  src=\"https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/media/use-cases/social-feed.svg\" alt=\"Microsoft\">\r\n",
                "<br>\r\n",
                " \r\n",
                "\r\n",
                "Let's start with setting up a couple of libraries in Python that we need. First, we'll use `requests`, which lets us make calls to REST interfaces. We'll then load a \"Pretty Printer\" (`pprint`) to display the data we return corectly: "
            ],
            "metadata": {
                "azdata_cell_guid": "b3165f72-c6c2-4779-97fb-3bb08668d583"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import requests\r\n",
                "# pprint is used to format the JSON response\r\n",
                "from pprint import pprint\r\n",
                "print(\"Libraries Loaded.\")"
            ],
            "metadata": {
                "azdata_cell_guid": "d2699d0e-5378-41f8-8e5a-bb793a44d80b"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Libraries Loaded.\n"
                }
            ],
            "execution_count": 1
        },
        {
            "cell_type": "code",
            "source": [
                "subscription_key = \"<YourSubscriptionKeyGoesHere>\"\r\n",
                "endpoint = \"<YourEndPointGoesHere>\"\r\n",
                "print(\"Keys and Access set.\")"
            ],
            "metadata": {
                "azdata_cell_guid": "d0e00665-760d-4408-9325-ab0f21bf9eac"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Keys and Access set.\n"
                }
            ],
            "execution_count": 2
        },
        {
            "cell_type": "markdown",
            "source": [
                "Now we'll add the Text Analytics base endpoint to form the language detection URL. For example: https://your-custom-subdomain.cognitiveservices.azure.com/text/analytics/v2.1/languages"
            ],
            "metadata": {
                "azdata_cell_guid": "654db16a-edc1-4466-8a6a-c8ca22faaaf9"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "language_api_url = \"https://<YourTextServiceURLGoesHere>/text/analytics/v2.1/languages\"\r\n",
                "print(\"API call point set.\")"
            ],
            "metadata": {
                "azdata_cell_guid": "09cd0bcc-5d4b-4470-b652-27548b474fd1"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "API call point set.\n"
                }
            ],
            "execution_count": 3
        },
        {
            "cell_type": "code",
            "source": [
                "# Set up a document. This would actually be real documents you send in - not something you have to set in code.\r\n",
                "documents = {\"documents\": [\r\n",
                "    {\"id\": \"1\", \"text\": \"This is a document written in English.\"},\r\n",
                "    {\"id\": \"2\", \"text\": \"Este es un document escrito en Español.\"},\r\n",
                "    {\"id\": \"3\", \"text\": \"这是一个用中文写的文件\"}\r\n",
                "]}\r\n",
                "print(\"Sample documents set.\")"
            ],
            "metadata": {
                "azdata_cell_guid": "16096144-fbf4-4218-b73b-603699b86873"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Sample documents set.\n"
                }
            ],
            "execution_count": 4
        },
        {
            "cell_type": "code",
            "source": [
                "# The call itself - simply send in what you want and get a prediction back\r\n",
                "headers = {\"Ocp-Apim-Subscription-Key\": subscription_key}\r\n",
                "response = requests.post(language_api_url, headers=headers, json=documents)\r\n",
                "languages = response.json()\r\n",
                "print(\"The predicted values for what you sent are:\")\r\n",
                "pprint(languages)"
            ],
            "metadata": {
                "azdata_cell_guid": "9aba298a-a31f-4c80-9004-bf4dda02de56"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "The predicted values for what you sent are:\n{'documents': [{'detectedLanguages': [{'iso6391Name': 'en',\n                                       'name': 'English',\n                                       'score': 1.0}],\n                'id': '1'},\n               {'detectedLanguages': [{'iso6391Name': 'es',\n                                       'name': 'Spanish',\n                                       'score': 1.0}],\n                'id': '2'},\n               {'detectedLanguages': [{'iso6391Name': 'zh_chs',\n                                       'name': 'Chinese_Simplified',\n                                       'score': 1.0}],\n                'id': '3'}],\n 'errors': []}\n"
                }
            ],
            "execution_count": 5
        }
    ]
}